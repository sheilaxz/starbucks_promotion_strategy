{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Exercise: Starbucks\n",
    "<br>\n",
    "\n",
    "<img src=\"https://opj.ca/wp-content/uploads/2018/02/New-Starbucks-Logo-1200x969.jpg\" width=\"200\" height=\"200\">\n",
    "<br>\n",
    "<br>\n",
    " \n",
    "#### Background Information\n",
    "\n",
    "The dataset you will be provided in this portfolio exercise was originally used as a take-home assignment provided by Starbucks for their job candidates. The data for this exercise consists of about 120,000 data points split in a 2:1 ratio among training and test files. In the experiment simulated by the data, an advertising promotion was tested to see if it would bring more customers to purchase a specific product priced at $10. Since it costs the company 0.15 to send out each promotion, it would be best to limit that promotion only to those that are most receptive to the promotion. Each data point includes one column indicating whether or not an individual was sent a promotion for the product, and one column indicating whether or not that individual eventually purchased that product. Each individual also has seven additional features associated with them, which are provided abstractly as V1-V7.\n",
    "\n",
    "#### Optimization Strategy\n",
    "\n",
    "Your task is to use the training data to understand what patterns in V1-V7 to indicate that a promotion should be provided to a user. Specifically, your goal is to maximize the following metrics:\n",
    "\n",
    "* **Incremental Response Rate (IRR)** \n",
    "\n",
    "IRR depicts how many more customers purchased the product with the promotion, as compared to if they didn't receive the promotion. Mathematically, it's the ratio of the number of purchasers in the promotion group to the total number of customers in the purchasers group (_treatment_) minus the ratio of the number of purchasers in the non-promotional group to the total number of customers in the non-promotional group (_control_).\n",
    "\n",
    "$$ IRR = \\frac{purch_{treat}}{cust_{treat}} - \\frac{purch_{ctrl}}{cust_{ctrl}} $$\n",
    "\n",
    "\n",
    "* **Net Incremental Revenue (NIR)**\n",
    "\n",
    "NIR depicts how much is made (or lost) by sending out the promotion. Mathematically, this is 10 times the total number of purchasers that received the promotion minus 0.15 times the number of promotions sent out, minus 10 times the number of purchasers who were not given the promotion.\n",
    "\n",
    "$$ NIR = (10\\cdot purch_{treat} - 0.15 \\cdot cust_{treat}) - 10 \\cdot purch_{ctrl}$$\n",
    "\n",
    "For a full description of what Starbucks provides to candidates see the [instructions available here](https://drive.google.com/open?id=18klca9Sef1Rs6q8DW4l7o349r8B70qXM).\n",
    "\n",
    "Below you can find the training data provided.  Explore the data and different optimization strategies.\n",
    "\n",
    "#### How To Test Your Strategy?\n",
    "\n",
    "When you feel like you have an optimization strategy, complete the `promotion_strategy` function to pass to the `test_results` function.  \n",
    "From past data, we know there are four possible outomes:\n",
    "\n",
    "Table of actual promotion vs. predicted promotion customers:  \n",
    "\n",
    "<table>\n",
    "<tr><th></th><th colspan = '2'>Actual</th></tr>\n",
    "<tr><th>Predicted</th><th>Yes</th><th>No</th></tr>\n",
    "<tr><th>Yes</th><td>I</td><td>II</td></tr>\n",
    "<tr><th>No</th><td>III</td><td>IV</td></tr>\n",
    "</table>\n",
    "\n",
    "The metrics are only being compared for the individuals we predict should obtain the promotion â€“ that is, quadrants I and II.  Since the first set of individuals that receive the promotion (in the training set) receive it randomly, we can expect that quadrants I and II will have approximately equivalent participants.  \n",
    "\n",
    "Comparing quadrant I to II then gives an idea of how well your promotion strategy will work in the future. \n",
    "\n",
    "Get started by reading in the data below.  See how each variable or combination of variables along with a promotion influences the chance of purchasing.  When you feel like you have a strategy for who should receive a promotion, test your strategy against the test dataset used in the final `test_results` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.443518</td>\n",
       "      <td>-1.165083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.159350</td>\n",
       "      <td>-0.645617</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.431659</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.588914</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.044332</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Promotion  purchase  V1         V2        V3  V4  V5  V6  V7\n",
       "0   1        No         0   2  30.443518 -1.165083   1   1   3   2\n",
       "1   3        No         0   3  32.159350 -0.645617   2   3   2   2\n",
       "2   4        No         0   2  30.431659  0.133583   1   1   4   2\n",
       "3   5        No         0   0  26.588914 -0.212728   2   1   4   2\n",
       "4   8       Yes         0   3  28.044332 -0.385883   1   1   2   2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in packages\n",
    "from itertools import combinations\n",
    "\n",
    "from test_results import test_results, score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "# import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, average_precision_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "# load in the data\n",
    "train_data = pd.DataFrame(pd.read_csv('./training.csv'))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Promotion    0\n",
       "purchase     0\n",
       "V1           0\n",
       "V2           0\n",
       "V3           0\n",
       "V4           0\n",
       "V5           0\n",
       "V6           0\n",
       "V7           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing value check\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84534 entries, 0 to 84533\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ID         84534 non-null  int64  \n",
      " 1   Promotion  84534 non-null  object \n",
      " 2   purchase   84534 non-null  int64  \n",
      " 3   V1         84534 non-null  int64  \n",
      " 4   V2         84534 non-null  float64\n",
      " 5   V3         84534 non-null  float64\n",
      " 6   V4         84534 non-null  int64  \n",
      " 7   V5         84534 non-null  int64  \n",
      " 8   V6         84534 non-null  int64  \n",
      " 9   V7         84534 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Change data type of variable \"Promotion\" to boolean\n",
    "#train_data['Promotion'] = list(map(lambda x: 1 if x == \"Yes\" else 0, train_data['Promotion']))\n",
    "#train_data['Promotion'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    84534.000000\n",
      "mean        29.973600\n",
      "std          5.010626\n",
      "min          7.104007\n",
      "25%         26.591501\n",
      "50%         29.979744\n",
      "75%         33.344593\n",
      "max         50.375913\n",
      "Name: V2, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1bb6604ba58>,\n",
       "  <matplotlib.lines.Line2D at 0x1bb6604bcf8>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1bb66062048>,\n",
       "  <matplotlib.lines.Line2D at 0x1bb66062320>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1bb6604b7f0>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x1bb660625f8>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x1bb660628d0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variable \"V2\"\n",
    "print (train_data['V2'].describe())\n",
    "plt.boxplot(train_data['V2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    84534.000000\n",
      "mean         0.000190\n",
      "std          1.000485\n",
      "min         -1.684550\n",
      "25%         -0.905350\n",
      "50%         -0.039572\n",
      "75%          0.826206\n",
      "max          1.691984\n",
      "Name: V3, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1bb663879e8>,\n",
       "  <matplotlib.lines.Line2D at 0x1bb66387cc0>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1bb66387f98>,\n",
       "  <matplotlib.lines.Line2D at 0x1bb6639a2b0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1bb66387780>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x1bb6639a588>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x1bb6639a860>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variable \"V3\"\n",
    "print (train_data['V3'].describe())\n",
    "plt.boxplot(train_data['V3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Variable 'V4':\n",
      "count    84534.000000\n",
      "mean         1.679608\n",
      "std          0.466630\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          2.000000\n",
      "max          2.000000\n",
      "Name: V4, dtype: float64\n",
      "2    57450\n",
      "1    27084\n",
      "Name: V4, dtype: int64\n",
      "\n",
      " Variable 'V5':\n",
      "count    84534.000000\n",
      "mean         2.327643\n",
      "std          0.841167\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max          4.000000\n",
      "Name: V5, dtype: float64\n",
      "3    32743\n",
      "2    31196\n",
      "1    15412\n",
      "4     5183\n",
      "Name: V5, dtype: int64\n",
      "\n",
      " Variable 'V6':\n",
      "count    84534.000000\n",
      "mean         2.502898\n",
      "std          1.117349\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          3.000000\n",
      "75%          4.000000\n",
      "max          4.000000\n",
      "Name: V6, dtype: float64\n",
      "3    21186\n",
      "4    21176\n",
      "2    21146\n",
      "1    21026\n",
      "Name: V6, dtype: int64\n",
      "\n",
      " Variable 'V7':\n",
      "count    84534.000000\n",
      "mean         1.701694\n",
      "std          0.457517\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          2.000000\n",
      "max          2.000000\n",
      "Name: V7, dtype: float64\n",
      "2    59317\n",
      "1    25217\n",
      "Name: V7, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Variable \"V4\"\n",
    "print (\" Variable 'V4':\")\n",
    "print (train_data['V4'].describe())\n",
    "print (train_data['V4'].value_counts())\n",
    "\n",
    "# Variable \"V5\"\n",
    "print (\"\\n Variable 'V5':\")\n",
    "print (train_data['V5'].describe())\n",
    "print (train_data['V5'].value_counts())\n",
    "\n",
    "# Variable \"V6\"\n",
    "print (\"\\n Variable 'V6':\")\n",
    "print (train_data['V6'].describe())\n",
    "print (train_data['V6'].value_counts())\n",
    "\n",
    "# Variable \"V7\"\n",
    "print (\"\\n Variable 'V7':\")\n",
    "print (train_data['V7'].describe())\n",
    "print (train_data['V7'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ID</th>\n",
       "      <th colspan=\"2\" halign=\"left\">purchase</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V4</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V5</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V6</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promotion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>63094.836661</td>\n",
       "      <td>62922</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>0</td>\n",
       "      <td>1.496277</td>\n",
       "      <td>1</td>\n",
       "      <td>29.976876</td>\n",
       "      <td>29.969732</td>\n",
       "      <td>-0.007099</td>\n",
       "      <td>-0.039572</td>\n",
       "      <td>1.680270</td>\n",
       "      <td>2</td>\n",
       "      <td>2.330638</td>\n",
       "      <td>2</td>\n",
       "      <td>2.501565</td>\n",
       "      <td>3</td>\n",
       "      <td>1.702205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>62847.675385</td>\n",
       "      <td>62717</td>\n",
       "      <td>0.017019</td>\n",
       "      <td>0</td>\n",
       "      <td>1.505028</td>\n",
       "      <td>2</td>\n",
       "      <td>29.970338</td>\n",
       "      <td>29.989227</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.047006</td>\n",
       "      <td>1.678949</td>\n",
       "      <td>2</td>\n",
       "      <td>2.324662</td>\n",
       "      <td>2</td>\n",
       "      <td>2.504225</td>\n",
       "      <td>3</td>\n",
       "      <td>1.701185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID         purchase               V1                V2  \\\n",
       "                   mean median      mean median      mean median       mean   \n",
       "Promotion                                                                     \n",
       "No         63094.836661  62922  0.007565      0  1.496277      1  29.976876   \n",
       "Yes        62847.675385  62717  0.017019      0  1.505028      2  29.970338   \n",
       "\n",
       "                            V3                  V4               V5         \\\n",
       "              median      mean    median      mean median      mean median   \n",
       "Promotion                                                                    \n",
       "No         29.969732 -0.007099 -0.039572  1.680270      2  2.330638      2   \n",
       "Yes        29.989227  0.007446  0.047006  1.678949      2  2.324662      2   \n",
       "\n",
       "                 V6               V7         \n",
       "               mean median      mean median  \n",
       "Promotion                                    \n",
       "No         2.501565      3  1.702205      2  \n",
       "Yes        2.504225      3  1.701185      2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See some statistics of variables in each group (Promotion and non-Promotion)\n",
    "GrpByProm = train_data.groupby('Promotion')\n",
    "GrpByProm.agg(['mean', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ID</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V4</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V5</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V6</th>\n",
       "      <th colspan=\"2\" halign=\"left\">V7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62942.917383</td>\n",
       "      <td>62784.5</td>\n",
       "      <td>1.501138</td>\n",
       "      <td>2</td>\n",
       "      <td>29.974547</td>\n",
       "      <td>29.978916</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>-0.039572</td>\n",
       "      <td>1.677929</td>\n",
       "      <td>2</td>\n",
       "      <td>2.326910</td>\n",
       "      <td>2</td>\n",
       "      <td>2.50309</td>\n",
       "      <td>3</td>\n",
       "      <td>1.701751</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65223.305769</td>\n",
       "      <td>65986.5</td>\n",
       "      <td>1.462500</td>\n",
       "      <td>1</td>\n",
       "      <td>29.897554</td>\n",
       "      <td>30.005909</td>\n",
       "      <td>-0.057137</td>\n",
       "      <td>-0.126150</td>\n",
       "      <td>1.814423</td>\n",
       "      <td>2</td>\n",
       "      <td>2.386538</td>\n",
       "      <td>3</td>\n",
       "      <td>2.48750</td>\n",
       "      <td>2</td>\n",
       "      <td>1.697115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                 V1                V2             \\\n",
       "                  mean   median      mean median       mean     median   \n",
       "purchase                                                                 \n",
       "0         62942.917383  62784.5  1.501138      2  29.974547  29.978916   \n",
       "1         65223.305769  65986.5  1.462500      1  29.897554  30.005909   \n",
       "\n",
       "                V3                  V4               V5              V6  \\\n",
       "              mean    median      mean median      mean median     mean   \n",
       "purchase                                                                  \n",
       "0         0.000905 -0.039572  1.677929      2  2.326910      2  2.50309   \n",
       "1        -0.057137 -0.126150  1.814423      2  2.386538      3  2.48750   \n",
       "\n",
       "                       V7         \n",
       "         median      mean median  \n",
       "purchase                          \n",
       "0             3  1.701751      2  \n",
       "1             2  1.697115      2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See some statistics of variables in each group (purchase and not-purchase)\n",
    "GrpByPur = train_data.groupby('purchase')\n",
    "GrpByPur.agg(['mean', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase</th>\n",
       "      <th>Promotion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>No</th>\n",
       "      <td>1.496738</td>\n",
       "      <td>29.976837</td>\n",
       "      <td>-0.007828</td>\n",
       "      <td>1.680175</td>\n",
       "      <td>2.330434</td>\n",
       "      <td>2.501661</td>\n",
       "      <td>1.702014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>1.505559</td>\n",
       "      <td>29.972246</td>\n",
       "      <td>0.009680</td>\n",
       "      <td>1.675672</td>\n",
       "      <td>2.323368</td>\n",
       "      <td>2.504527</td>\n",
       "      <td>1.701486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>No</th>\n",
       "      <td>1.435737</td>\n",
       "      <td>29.982026</td>\n",
       "      <td>0.088530</td>\n",
       "      <td>1.692790</td>\n",
       "      <td>2.357367</td>\n",
       "      <td>2.489028</td>\n",
       "      <td>1.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>1.474341</td>\n",
       "      <td>29.860180</td>\n",
       "      <td>-0.121587</td>\n",
       "      <td>1.868239</td>\n",
       "      <td>2.399445</td>\n",
       "      <td>2.486824</td>\n",
       "      <td>1.683773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          V1         V2        V3        V4        V5  \\\n",
       "                        mean       mean      mean      mean      mean   \n",
       "purchase Promotion                                                      \n",
       "0        No         1.496738  29.976837 -0.007828  1.680175  2.330434   \n",
       "         Yes        1.505559  29.972246  0.009680  1.675672  2.323368   \n",
       "1        No         1.435737  29.982026  0.088530  1.692790  2.357367   \n",
       "         Yes        1.474341  29.860180 -0.121587  1.868239  2.399445   \n",
       "\n",
       "                          V6        V7  \n",
       "                        mean      mean  \n",
       "purchase Promotion                      \n",
       "0        No         2.501661  1.702014  \n",
       "         Yes        2.504527  1.701486  \n",
       "1        No         2.489028  1.727273  \n",
       "         Yes        2.486824  1.683773  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average value of each variable in four sub-groups: purchase and non-purchase, promotion and non-promotion\n",
    "variables = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7']\n",
    "train_data.groupby(['purchase', 'Promotion'])[variables].agg(['mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After basic data exploration, we could find that the data seems reasonable in each variable, and some differences could be observed between sub-groups. No more data cleaning is needed in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then test whether the two groups (experiment group and control group) have equal size. The null hypothesis is the two groups have equal size. To reject this hypothesis, p-value should be smaller than 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of individuals in the training dataset: 84534\n",
      "Promotion Group Size: 42364\n",
      "Non-Promotion Group Size: 42170\n"
     ]
    }
   ],
   "source": [
    "# The number of total individuals, and numbers of individuals in each group\n",
    "N = train_data.shape[0]\n",
    "n_exp = train_data[train_data['Promotion'] == \"Yes\"].shape[0]\n",
    "n_ctr = train_data[train_data['Promotion'] == \"No\"].shape[0]\n",
    "\n",
    "print (\"Total number of individuals in the training dataset: {}\".format(N))\n",
    "print (\"Promotion Group Size: {}\".format(n_exp))\n",
    "print (\"Non-Promotion Group Size: {}\".format(n_ctr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z score: -0.6638066506192843\n",
      "p-value: 0.5068140685419046\n"
     ]
    }
   ],
   "source": [
    "# Compute a z-score and p-value\n",
    "p = 0.5\n",
    "sd = np.sqrt(p * (1-p) * N)\n",
    "\n",
    "z = ((n_ctr + 0.5) - p * N) / sd\n",
    "\n",
    "print(\"z score:\", z)\n",
    "print(\"p-value:\", 2 * sp.stats.norm.cdf(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the p-value is 0.5068 > 0.05, which means that both groups are equal-sized.  \n",
    "\n",
    "We then see the purchase ratio and the two metrics (IRR and NIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchase rate in experiment group: 0.017019167217448776\n",
      "Purchase rate in control group: 0.007564619397676073\n"
     ]
    }
   ],
   "source": [
    "# Purchase rate in each group\n",
    "pur_ratio_exp = train_data[(train_data['purchase'] == 1) & (train_data['Promotion'] == 'Yes')].shape[0] / n_exp\n",
    "pur_ratio_ctr = train_data[(train_data['purchase'] == 1) & (train_data['Promotion'] == 'No')].shape[0] / n_ctr\n",
    "print (\"Purchase rate in experiment group: {}\".format(pur_ratio_exp))\n",
    "print (\"Purchase rate in control group: {}\".format(pur_ratio_ctr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for the two basic metrics: IRR, and NIR\n",
    "\n",
    "def getIRR(df):\n",
    "    '''\n",
    "    A function calculating IRR from the dataframe with columns for 'Promotion' and 'purchase'\n",
    "    \n",
    "    Input:\n",
    "        df: a dataframe with columns 'Promotion' and 'purchase'\n",
    "    \n",
    "    Output: \n",
    "        irr: a value of the incremental response rate (IRR)\n",
    "    '''\n",
    "    \n",
    "    # Number of individuals in Promotion and Non-promotion groups\n",
    "    n_exp = df[df['Promotion'] == \"Yes\"].shape[0]\n",
    "    n_ctr = df[df['Promotion'] == \"No\"].shape[0]\n",
    "    \n",
    "    # Purchase rate in Promotion and Non-promotion groups\n",
    "    pur_ratio_exp = df[(df['purchase'] == 1) & (df['Promotion'] == 'Yes')].shape[0] / n_exp\n",
    "    pur_ratio_ctr = df[(df['purchase'] == 1) & (df['Promotion'] == 'No')].shape[0] / n_ctr\n",
    "\n",
    "    # Calculate IRR\n",
    "    irr = pur_ratio_exp - pur_ratio_ctr\n",
    "    \n",
    "    return irr\n",
    "\n",
    "\n",
    "def getNIR(df):\n",
    "    '''\n",
    "    A function calculating NIR from the dataframe with columns 'Promotion' and 'purchase'\n",
    "    \n",
    "    Input:\n",
    "        df: a dataframe with columns 'Promotion' and 'purchase'\n",
    "    \n",
    "    Output: \n",
    "        irr: a value of the net incremental revenue (NIR)\n",
    "    '''\n",
    "\n",
    "    # Number of Purchases in Promotion and Non-promotion groups\n",
    "    pur_exp = df[(df['purchase'] == 1) & (df['Promotion'] == 'Yes')].shape[0]\n",
    "    pur_ctr = df[(df['purchase'] == 1) & (df['Promotion'] == 'No')].shape[0]\n",
    "\n",
    "    # Number of Promotions sent out\n",
    "    n_exp = df[df['Promotion'] == \"Yes\"].shape[0]\n",
    "    \n",
    "    # Calculate NIR\n",
    "    nir = (10 * pur_exp - 0.15 * n_exp) - 10 * pur_ctr\n",
    "    \n",
    "    return nir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRR: 0.009454547819772702\n",
      "NIR: -2334.5999999999995\n"
     ]
    }
   ],
   "source": [
    "# Now we could calculate IRR and NIR for our original training dataframe.\n",
    "print (\"IRR:\", getIRR(train_data))\n",
    "print (\"NIR:\", getNIR(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function calculating the confidence intervals for IRR and NIR\n",
    "# Use bootstrap method\n",
    "\n",
    "def getCI(df, c = 0.95, n_trials = 10000):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute a confidence interval for a quantile of a dataset using a bootstrap method.\n",
    "    \n",
    "    Input:\n",
    "        df: a dataframe with columns 'Promotion' and 'purchase' \n",
    "        c: confidence interval level, with a default value of 0.95 (95%)\n",
    "        n_trials: number of bootstrap trials to conduct, with a default value of 10000\n",
    "    \n",
    "    Output:\n",
    "        Confidence interval or IRR and NIR\n",
    "    \"\"\"\n",
    "        \n",
    "    # initialize IRR and NIR lists to save IRR and NIR values obtained in each trial\n",
    "    n_points = df.shape[0]\n",
    "    irr_list = []\n",
    "    nir_list = []\n",
    "    \n",
    "    # For each trial...\n",
    "    for _ in range(n_trials):\n",
    "        # draw a random sample from the data with replacement...\n",
    "        sample = np.random.choice(df.index, df.shape[0], replace = True)\n",
    "        \n",
    "        # compute IRR and NIR for the sample\n",
    "        sample_irr = getIRR(df.iloc[sample])\n",
    "        sample_nir = getNIR(df.iloc[sample])\n",
    "        \n",
    "        # and add the value to the list of IRR and NIR\n",
    "        irr_list.append(sample_irr)\n",
    "        nir_list.append(sample_nir)\n",
    "        \n",
    "    # Compute the confidence interval bounds for IRR and NIR\n",
    "    irr_CI = [np.percentile(irr_list, (1 - c)/2 * 100), np.percentile(irr_list, (1 + c)/2 * 100)]\n",
    "    nir_CI = [np.percentile(nir_list, (1 - c)/2 * 100), np.percentile(nir_list, (1 + c)/2 * 100)]\n",
    "    \n",
    "    print (\"IRR {} Confidence Interval: {} \\nNir {} Confidence Interval: {}\".format(c, irr_CI, c, nir_CI))\n",
    "    \n",
    "    return irr_CI, nir_CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now able to calculate the CIs of IRR and NIR for the train_data.  \n",
    "\n",
    "Notice that there are two metrics here. Thus, we use Bonferroni Correction:  \n",
    "$$\\text{Bonferroni Correction} = \\frac{\\alpha}  {\\text{number of metrics}} = \\frac{0.5}{2} = 0.025 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRR 0.975 Confidence Interval: [0.007734642906383367, 0.011129844443801957] \n",
      "Nir 0.975 Confidence Interval: [-3069.1549999999997, -1625.88]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.007734642906383367, 0.011129844443801957], [-3069.1549999999997, -1625.88])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getCI(train_data, 0.975, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From previous exploration, we know several variables are categorical variables, which could be transformed to dummy variables before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set X variable and get dummy variables for each feature within\n",
    "X = train_data.iloc[:,3:]\n",
    "X = pd.get_dummies(data = X, columns=['V1','V4', 'V5','V6','V7'], drop_first = True)\n",
    "y = train_data['purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V1_1</th>\n",
       "      <th>V1_2</th>\n",
       "      <th>V1_3</th>\n",
       "      <th>V4_2</th>\n",
       "      <th>V5_2</th>\n",
       "      <th>V5_3</th>\n",
       "      <th>V5_4</th>\n",
       "      <th>V6_2</th>\n",
       "      <th>V6_3</th>\n",
       "      <th>V6_4</th>\n",
       "      <th>V7_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66588</th>\n",
       "      <td>34.470493</td>\n",
       "      <td>-1.078506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62125</th>\n",
       "      <td>28.065819</td>\n",
       "      <td>-1.165083</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27827</th>\n",
       "      <td>27.142590</td>\n",
       "      <td>-1.511395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66648</th>\n",
       "      <td>28.782344</td>\n",
       "      <td>-1.078506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47392</th>\n",
       "      <td>39.605508</td>\n",
       "      <td>-0.645617</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              V2        V3  V1_1  V1_2  V1_3  V4_2  V5_2  V5_3  V5_4  V6_2  \\\n",
       "66588  34.470493 -1.078506     0     0     1     0     0     0     0     0   \n",
       "62125  28.065819 -1.165083     1     0     0     0     0     0     0     0   \n",
       "27827  27.142590 -1.511395     1     0     0     0     0     1     0     0   \n",
       "66648  28.782344 -1.078506     0     0     1     0     0     0     0     0   \n",
       "47392  39.605508 -0.645617     0     1     0     1     0     1     0     0   \n",
       "\n",
       "       V6_3  V6_4  V7_2  \n",
       "66588     0     0     1  \n",
       "62125     1     0     0  \n",
       "27827     1     0     1  \n",
       "66648     0     0     1  \n",
       "47392     0     0     1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Further split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16678    21]\n",
      " [  208     0]]\n",
      "Accuracy: 0.9864553143668303\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Fit Gradient Boosting Classifier\n",
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction, present the confusion matrix and accuracy\n",
    "y_pred = GBC.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "(tn, fp, fn, tp) = confusion_matrix(y_test, y_pred).ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "\n",
    "print ('Accuracy: {}'.format(accuracy))\n",
    "print ('Precision: {}'.format(precision))\n",
    "print ('Recall: {}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRR: -0.012317896482293023\n",
      "NIR: -2083.15\n"
     ]
    }
   ],
   "source": [
    "y_pred = list(map(lambda x: \"Yes\" if x == 1 else \"No\", y_pred))\n",
    "fit_df = pd.DataFrame({\"Promotion\": y_pred, \"purchase\": y_test})\n",
    "print (\"IRR:\", getIRR(fit_df))\n",
    "print (\"NIR:\", getNIR(fit_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see that the model prediction results are worse than the default promotion strategy. This is because the dataset is highly imbalanced due to too few people purchase the product, which can lead to biased algorithm: we could obtain a very high accuracy by always predicting that the customer will not purchase the product. \n",
    "\n",
    "To deal with the algorithm learning with imbalanced dataset, a downsample method and an upsampling method could be applied, such that the number of individuals who purchase the product and do not purchase the product are balanced in the training set. \n",
    "\n",
    "Then we re-train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DownSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DownSampling Method\n",
    "promo_sample_idx = np.random.choice(train_data[train_data[\"purchase\"] == 0].index, \n",
    "                                    train_data[train_data[\"purchase\"] == 1].shape[0], \n",
    "                                    replace = False)\n",
    "promo_sample = train_data.iloc[promo_sample_idx]\n",
    "dns_df = pd.concat([promo_sample, train_data[train_data[\"purchase\"] == 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V1_1</th>\n",
       "      <th>V1_2</th>\n",
       "      <th>V1_3</th>\n",
       "      <th>V4_2</th>\n",
       "      <th>V5_2</th>\n",
       "      <th>V5_3</th>\n",
       "      <th>V5_4</th>\n",
       "      <th>V6_2</th>\n",
       "      <th>V6_3</th>\n",
       "      <th>V6_4</th>\n",
       "      <th>V7_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81188</th>\n",
       "      <td>29.335677</td>\n",
       "      <td>1.345672</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31884</th>\n",
       "      <td>22.808890</td>\n",
       "      <td>-0.559039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39566</th>\n",
       "      <td>24.581469</td>\n",
       "      <td>0.306739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54153</th>\n",
       "      <td>32.660111</td>\n",
       "      <td>0.047006</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17446</th>\n",
       "      <td>31.074061</td>\n",
       "      <td>-1.338239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              V2        V3  V1_1  V1_2  V1_3  V4_2  V5_2  V5_3  V5_4  V6_2  \\\n",
       "81188  29.335677  1.345672     1     0     0     1     1     0     0     0   \n",
       "31884  22.808890 -0.559039     0     0     0     1     0     0     0     0   \n",
       "39566  24.581469  0.306739     0     1     0     1     0     1     0     0   \n",
       "54153  32.660111  0.047006     1     0     0     1     0     1     0     0   \n",
       "17446  31.074061 -1.338239     0     1     0     1     0     1     0     0   \n",
       "\n",
       "       V6_3  V6_4  V7_2  \n",
       "81188     0     1     1  \n",
       "31884     1     0     0  \n",
       "39566     1     0     1  \n",
       "54153     0     1     1  \n",
       "17446     0     1     1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set X variable and get dummy variables for each feature within\n",
    "X = dns_df.iloc[:,3:]\n",
    "X = pd.get_dummies(data = X, columns=['V1','V4', 'V5','V6','V7'], drop_first = True)\n",
    "y = dns_df['purchase']\n",
    "\n",
    "# Further split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104 109]\n",
      " [ 72 131]]\n",
      "Accuracy: 0.5649038461538461\n",
      "Precision: 0.5458333333333333\n",
      "Recall: 0.645320197044335\n"
     ]
    }
   ],
   "source": [
    "# Fit Gradient Boosting Classifier\n",
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction, present the confusion matrix and accuracy\n",
    "y_pred = GBC.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "(tn, fp, fn, tp) = confusion_matrix(y_test, y_pred).ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "\n",
    "print ('Accuracy: {}'.format(accuracy))\n",
    "print ('Precision: {}'.format(precision))\n",
    "print ('Recall: {}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRR: 0.13674242424242417\n",
      "NIR: 554.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = list(map(lambda x: \"Yes\" if x == 1 else \"No\", y_pred))\n",
    "fit_df = pd.DataFrame({\"Promotion\": y_pred, \"purchase\": y_test})\n",
    "print (\"IRR:\", getIRR(fit_df))\n",
    "print (\"NIR:\", getNIR(fit_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UpSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UpSampling Method\n",
    "promo_sample_idx = np.random.choice(train_data[train_data[\"purchase\"] == 1].index, \n",
    "                                    train_data[train_data[\"purchase\"] == 0].shape[0], \n",
    "                                    replace = True)\n",
    "promo_sample = train_data.iloc[promo_sample_idx]\n",
    "ups_df = pd.concat([promo_sample, train_data[train_data[\"purchase\"] == 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V1_1</th>\n",
       "      <th>V1_2</th>\n",
       "      <th>V1_3</th>\n",
       "      <th>V4_2</th>\n",
       "      <th>V5_2</th>\n",
       "      <th>V5_3</th>\n",
       "      <th>V5_4</th>\n",
       "      <th>V6_2</th>\n",
       "      <th>V6_3</th>\n",
       "      <th>V6_4</th>\n",
       "      <th>V7_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14335</th>\n",
       "      <td>37.905682</td>\n",
       "      <td>-1.165083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34700</th>\n",
       "      <td>26.773433</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59062</th>\n",
       "      <td>28.656123</td>\n",
       "      <td>-0.126150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57354</th>\n",
       "      <td>35.972148</td>\n",
       "      <td>-1.684550</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10270</th>\n",
       "      <td>30.900568</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              V2        V3  V1_1  V1_2  V1_3  V4_2  V5_2  V5_3  V5_4  V6_2  \\\n",
       "14335  37.905682 -1.165083     0     0     1     1     0     1     0     0   \n",
       "34700  26.773433 -0.212728     0     0     0     0     1     0     0     1   \n",
       "59062  28.656123 -0.126150     0     0     1     0     0     0     0     1   \n",
       "57354  35.972148 -1.684550     0     1     0     1     0     1     0     0   \n",
       "10270  30.900568  0.133583     0     1     0     1     0     0     1     0   \n",
       "\n",
       "       V6_3  V6_4  V7_2  \n",
       "14335     0     1     1  \n",
       "34700     0     0     1  \n",
       "59062     0     0     1  \n",
       "57354     0     1     1  \n",
       "10270     0     1     1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set X variable and get dummy variables for each feature within\n",
    "X = ups_df.iloc[:,3:]\n",
    "X = pd.get_dummies(data = X, columns=['V1','V4', 'V5','V6','V7'], drop_first = True)\n",
    "y = ups_df['purchase']\n",
    "\n",
    "# Further split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9817  6991]\n",
      " [ 4684 11906]]\n",
      "Accuracy: 0.6504281693514582\n",
      "Precision: 0.6300470974228713\n",
      "Recall: 0.7176612417118746\n"
     ]
    }
   ],
   "source": [
    "# Fit Gradient Boosting Classifier\n",
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction, present the confusion matrix and accuracy\n",
    "y_pred = GBC.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "(tn, fp, fn, tp) = confusion_matrix(y_test, y_pred).ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "\n",
    "print ('Accuracy: {}'.format(accuracy))\n",
    "print ('Precision: {}'.format(precision))\n",
    "print ('Recall: {}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRR: 0.3070348913681165\n",
      "NIR: 69385.45\n"
     ]
    }
   ],
   "source": [
    "y_pred = list(map(lambda x: \"Yes\" if x == 1 else \"No\", y_pred))\n",
    "fit_df = pd.DataFrame({\"Promotion\": y_pred, \"purchase\": y_test})\n",
    "print (\"IRR:\", getIRR(fit_df))\n",
    "print (\"NIR:\", getNIR(fit_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we could see that upsampling show better performance than downsampling. This may be because down sampling omit too many data points thus cause significant information loss.  \n",
    "Thus, we use upsampling to further improve the learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('clf', GradientBoostingClassifier())],\n",
       " 'verbose': False,\n",
       " 'clf': GradientBoostingClassifier(),\n",
       " 'clf__ccp_alpha': 0.0,\n",
       " 'clf__criterion': 'friedman_mse',\n",
       " 'clf__init': None,\n",
       " 'clf__learning_rate': 0.1,\n",
       " 'clf__loss': 'deviance',\n",
       " 'clf__max_depth': 3,\n",
       " 'clf__max_features': None,\n",
       " 'clf__max_leaf_nodes': None,\n",
       " 'clf__min_impurity_decrease': 0.0,\n",
       " 'clf__min_impurity_split': None,\n",
       " 'clf__min_samples_leaf': 1,\n",
       " 'clf__min_samples_split': 2,\n",
       " 'clf__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__n_estimators': 100,\n",
       " 'clf__n_iter_no_change': None,\n",
       " 'clf__presort': 'deprecated',\n",
       " 'clf__random_state': None,\n",
       " 'clf__subsample': 1.0,\n",
       " 'clf__tol': 0.0001,\n",
       " 'clf__validation_fraction': 0.1,\n",
       " 'clf__verbose': 0,\n",
       " 'clf__warm_start': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_GBC = Pipeline([\n",
    "            ('clf', GradientBoostingClassifier())\n",
    "        ])\n",
    "pipeline_GBC.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('clf', GradientBoostingClassifier())]),\n",
       "             param_grid={})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model():\n",
    "\n",
    "    \"\"\"\n",
    "    A machine learning pipeline contains: \n",
    "        - Gradient Boosting Classification model training\n",
    "        - gridsearch hyperparameters tuning\n",
    "    \n",
    "    Inputs: \n",
    "        None\n",
    "    Output: \n",
    "        cv: pipeline represented by a GridSearchCV object\n",
    "    \"\"\"\n",
    "\n",
    "    pipeline_GBC = Pipeline([\n",
    "            ('clf', GradientBoostingClassifier())\n",
    "        ])\n",
    "        \n",
    "    parameters = {\n",
    "#        'clf__n_estimators': [50, 100, 200],\n",
    "#        'clf__max_depth': [5, 10, None],\n",
    "#        'clf__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    cv = GridSearchCV(pipeline_GBC, param_grid=parameters)\n",
    "    \n",
    "    return cv\n",
    "\n",
    "model_GBC = build_model()\n",
    "model_GBC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': None}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GBC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotion_strategy(df):\n",
    "    '''\n",
    "    INPUT \n",
    "    df - a dataframe with *only* the columns V1 - V7 (same as train_data)\n",
    "\n",
    "    OUTPUT\n",
    "    promotion_df - np.array with the values\n",
    "                   'Yes' or 'No' related to whether or not an \n",
    "                   individual should recieve a promotion \n",
    "                   should be the length of df.shape[0]\n",
    "                \n",
    "    Ex:\n",
    "    INPUT: df\n",
    "    \n",
    "    V1\tV2\t  V3\tV4\tV5\tV6\tV7\n",
    "    2\t30\t-1.1\t1\t1\t3\t2\n",
    "    3\t32\t-0.6\t2\t3\t2\t2\n",
    "    2\t30\t0.13\t1\t1\t4\t2\n",
    "    \n",
    "    OUTPUT: promotion\n",
    "    \n",
    "    array(['Yes', 'Yes', 'No'])\n",
    "    indicating the first two users would recieve the promotion and \n",
    "    the last should not.\n",
    "    '''\n",
    "    \n",
    "    X = pd.get_dummies(data = df, columns=['V1','V4', 'V5','V6','V7'], drop_first = True)\n",
    "    y_pred = model_GBC.predict(X)\n",
    "    promotion = np.array(list(map(lambda x: \"Yes\" if x == 1 else \"No\", y_pred)))\n",
    "    \n",
    "    return promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job!  See how well your strategy worked on our test data below!\n",
      "\n",
      "Your irr with this strategy is 0.0200.\n",
      "\n",
      "Your nir with this strategy is 426.20.\n",
      "We came up with a model with an irr of 0.0188 and an nir of 189.45 on the test set.\n",
      "\n",
      " How did you do?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.020027930048123605, 426.20000000000005)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will test your results, and provide you back some information \n",
    "# on how well your promotion_strategy will work in practice\n",
    "\n",
    "test_results(promotion_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRR obtained from our Gradient Boosting Classifier model is out of the 97.5% confidence level of the original promotion strategy, which means that the proposed strategy is definitely better than the default strategy. Meanwhile, the IRR and NIR obtained from our model are also higher than the results given by the embedded algorithm (created by Udacity). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's export the trained model as pickle file.\n",
    "\n",
    "pickle_out = open(\"model_GBC.pkl\", 'wb')\n",
    "pickle.dump(model_GBC, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
